{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "\n\nOl\u00e1 estudante!\n\nMe chamo Rafael Meirelles e irei revisar o seu projeto hoje e em eventuais futuras submiss\u00f5es at\u00e9 que ele cumpra todos os requisitos para o aceite.\nConte comigo nessa jornada e n\u00e3o se preocupe se precisar ajustar alguns detalhes, \u00e9 parte do processo e fundamental para que voc\u00ea exercite os conceitos que vem aprendendo e assim melhore a qualidade dos seus c\u00f3digos e an\u00e1lises.\n\n**Pe\u00e7o que mantenha e n\u00e3o altereos coment\u00e1rios que eu fizer por aqui para que possamos nos localizar posteriormente, ok?**\n\nMais uma coisa, vamos utilizar um c\u00f3digo de cores para voc\u00ea entender os meus feedbacks no seu notebook. Funciona assim:\n\n\n<div class=\"alert alert-danger\">\n<strong>Vermelho</strong>\n\nErro que precisa ser consertado, caso contr\u00e1rio, seu projeto n\u00e3o pode ser aceito\n\n</div>\n\n<div class=\"alert alert-warning\">\n<strong>Amarelo</strong>\n\nAlerta de um erro n\u00e3o cr\u00edtco, mas que pode ser corrigido para melhoria geral no seu c\u00f3digo/an\u00e1lise\n\n</div>\n\n<div class=\"alert alert-success\">\n<strong>Verde</strong>\n\nElogios\n</div>\n\n<div class=\"alert alert-info\">\n<strong>Coment\u00e1rio do estudante</strong>\n\nUse uma caixa azul como essa para eventuais coment\u00e1rios que voc\u00ea gostaria de fazer para mim.\n</div>\n\n\n\n\n\n"}, {"cell_type": "code", "execution_count": null, "metadata": {"trusted": true}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {"trusted": true}, "outputs": [], "source": ""}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-danger\">\n<strong>Coment\u00e1rio do revisor v1</strong>\n\nEstamos no caminho certo com essa vers\u00e3o, mas retocar os pontos indicados abaixo nos far\u00e1 chegar em um resultado ainda mais incr\u00edvel.\n    \nConte comigo para ajud\u00e1-lo (a) em qualquer quest\u00e3o que possa vir a ter! Lembre-se de usar as caixas azuis para se comunicar comigo.\n    \nAt\u00e9 breve.\n</div>\n"}, {"cell_type": "markdown", "metadata": {"id": "E0vqbgi9ay0H"}, "source": "# Se liga na m\u00fasica"}, {"cell_type": "markdown", "metadata": {"id": "fhq_eyov_Zcs"}, "source": "# Conte\u00fado <a id='back'></a>\n\n* [Introdu\u00e7\u00e3o](#intro)\n* [Etapa 1. Vis\u00e3o geral dos dados](#data_review)\n    * [Conclus\u00f5es](#data_review_conclusions)\n* [Etapa 2. Pr\u00e9-processamento de dados](#data_preprocessing)\n    * [2.1 Estilo do cabe\u00e7alho](#header_style)\n    * [2.2 Valores ausentes](#missing_values)\n    * [2.3 Duplicados](#duplicates)\n    * [2.4 Conclus\u00f5es](#data_preprocessing_conclusions)\n* [Etapa 3. Teste da hip\u00f3tese](#hypothesis)\n    * [3.1 Hip\u00f3tese 1: atividade dos usu\u00e1rios nas duas cidades](#activity)\n* [Conclus\u00f5es](#end)"}, {"cell_type": "markdown", "metadata": {"id": "VUC88oWjTJw2"}, "source": "## Introdu\u00e7\u00e3o <a id='intro'></a>\nO trabalho de um analista \u00e9 analisar dados para obter percep\u00e7\u00f5es valiosas dos dados e tomar decis\u00f5es fundamentadas neles. Esse processo consiste em v\u00e1rias etapas, como vis\u00e3o geral dos dados, pr\u00e9-processamento dos dados e testes de hip\u00f3teses.\n\nSempre que fazemos uma pesquisa, precisamos formular uma hip\u00f3tese que depois poderemos testar. \u00c0s vezes n\u00f3s aceitamos essas hip\u00f3teses; outras vezes, n\u00f3s as rejeitamos. Para fazer as escolhas certas, um neg\u00f3cio deve ser capaz de entender se est\u00e1 fazendo as suposi\u00e7\u00f5es certas ou n\u00e3o.\n\nNeste projeto, voc\u00ea vai comparar as prefer\u00eancias musicais dos habitantes de Springfild e Shelbyville. Voc\u00ea vai estudar os dados de um servi\u00e7o de streaming de m\u00fasica online para testar a hip\u00f3tese apresentada abaixo e comparar o comportamento dos usu\u00e1rios dessas duas cidades.\n\n### Objetivo:\nTeste a hip\u00f3tese:\n1. A atividade dos usu\u00e1rios \u00e9 diferente dependendo do dia da semana e da cidade.\n\n\n### Etapas\nOs dados sobre o comportamento do usu\u00e1rio s\u00e3o armazenados no arquivo `/datasets/music_project_en.csv`. N\u00e3o h\u00e1 informa\u00e7\u00f5es sobre a qualidade dos dados, ent\u00e3o ser\u00e1 necess\u00e1rio examin\u00e1-los antes de testar a hip\u00f3tese.\n\nPrimeiro, voc\u00ea avaliar\u00e1 a qualidade dos dados e ver\u00e1 se seus problemas s\u00e3o significativos. Depois, durante o pr\u00e9-processamento dos dados, voc\u00ea tentar\u00e1 tratar dos problemas mais cr\u00edticos.\n\nO seu projeto consistir\u00e1 em tr\u00eas etapas:\n 1. Vis\u00e3o geral dos dados\n 2. Pr\u00e9-processamento de dados\n 3. Teste da hip\u00f3tese\n\n\n\n\n\n\n"}, {"cell_type": "markdown", "metadata": {"id": "hDt6pg-Rw-1U"}, "source": "[Voltar ao \u00cdndice](#back)"}, {"cell_type": "markdown", "metadata": {"id": "Ml1hmfXC_Zcs"}, "source": "## Etapa 1. Vis\u00e3o geral dos dados <a id='data_review'></a>\n\nAbra os dados e examine-os."}, {"cell_type": "markdown", "metadata": {"id": "57eAOGIz_Zcs"}, "source": "Voc\u00ea precisar\u00e1 da `pandas`, ent\u00e3o, importe-a."}, {"cell_type": "code", "execution_count": 3, "metadata": {"id": "AXN7PHPN_Zcs", "trusted": true}, "outputs": [], "source": "# importando pandas\nimport pandas as pd"}, {"cell_type": "markdown", "metadata": {"id": "SG23P8tt_Zcs"}, "source": "Leia o arquivo `music_project_en.csv` da pasta `/datasets/` e salve-o na vari\u00e1vel `df`:"}, {"cell_type": "code", "execution_count": 4, "metadata": {"id": "fFVu7vqh_Zct", "scrolled": true, "trusted": true}, "outputs": [], "source": "# lendo o arquivo e armazenando em df\ndf = pd.read_csv('/datasets/music_project_en.csv')"}, {"cell_type": "markdown", "metadata": {"id": "rDoOMd3uTqnZ"}, "source": "Imprima as primeiras 10 linhas da tabela:"}, {"cell_type": "code", "execution_count": 5, "metadata": {"id": "oWTVX3gW_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "     userID                        Track            artist   genre  \\\n0  FFB692EC            Kamigata To Boots  The Mass Missile    rock   \n1  55204538  Delayed Because of Accident  Andreas R\u00f6nnberg    rock   \n2    20EC38            Funicul\u00ec funicul\u00e0       Mario Lanza     pop   \n3  A3DD03C9        Dragons in the Sunset        Fire + Ice    folk   \n4  E2DC1FAE                  Soul People        Space Echo   dance   \n5  842029A1                       Chains          Obladaet  rusrap   \n6  4CB90AA5                         True      Roman Messer   dance   \n7  F03E1C1F             Feeling This Way   Polina Griffith   dance   \n8  8FA1D3BE                     L\u2019estate       Julia Dalia  ruspop   \n9  E772D5C0                    Pessimist               NaN   dance   \n\n        City        time        Day  \n0  Shelbyville  20:28:33  Wednesday  \n1  Springfield  14:07:09     Friday  \n2  Shelbyville  20:58:07  Wednesday  \n3  Shelbyville  08:37:09     Monday  \n4  Springfield  08:34:34     Monday  \n5  Shelbyville  13:09:41     Friday  \n6  Springfield  13:00:07  Wednesday  \n7  Springfield  20:47:49  Wednesday  \n8  Springfield  09:17:40     Friday  \n9  Shelbyville  21:20:49  Wednesday  \n"}], "source": "# obtenha as 10 primeiras 10 linhas da tabela df\nprint(df.head(10))"}, {"cell_type": "markdown", "metadata": {"id": "EO73Kwic_Zct"}, "source": "Obtenha informa\u00e7\u00f5es gerais sobre a tabela usando um comando. Voc\u00ea conhece o m\u00e9todo para exibir informa\u00e7\u00f5es gerais que precisamos obter."}, {"cell_type": "code", "execution_count": 6, "metadata": {"id": "DSf2kIb-_Zct", "scrolled": true, "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 65079 entries, 0 to 65078\nData columns (total 7 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0     userID  65079 non-null  object\n 1   Track     63736 non-null  object\n 2   artist    57512 non-null  object\n 3   genre     63881 non-null  object\n 4     City    65079 non-null  object\n 5   time      65079 non-null  object\n 6   Day       65079 non-null  object\ndtypes: object(7)\nmemory usage: 3.5+ MB\nNone\n"}], "source": "# obtendo informa\u00e7\u00f5es gerais sobre os nossos dados\nprint(df.info())"}, {"cell_type": "markdown", "metadata": {"id": "TaQ2Iwbr_Zct"}, "source": "Aqui est\u00e3o as nossas observa\u00e7\u00f5es sobre a tabela. Ela cont\u00e9m sete colunas. Elas armazenam o mesmo tipo de dado: `object`.\n\nDe acordo com a documenta\u00e7\u00e3o:\n- `' userID'` \u2014 identifica\u00e7\u00e3o do usu\u00e1rio\n- `'Track'` \u2014 t\u00edtulo da m\u00fasica\n- `'artist'` \u2014 nome do artista\n- `'genre'` \u2014 g\u00eanero da m\u00fasica\n- `'City'` \u2014 cidade do usu\u00e1rio\n- `'time'` \u2014 o tempo exato que a m\u00fasica foi reproduzida\n- `'Day'` \u2014 dia da semana\n\nPodemos ver tr\u00eas problemas de estilo nos cabe\u00e7alhos da tabela:\n1. Alguns cabe\u00e7alhos s\u00e3o escritos em letras mai\u00fasculas, outros est\u00e3o em min\u00fasculas.\n2. Alguns cabe\u00e7alhos cont\u00eam espa\u00e7os.\n3. A coluna `' userID'` deveria estar em `snake_case` por ter duas palavras.\n\n\n"}, {"cell_type": "markdown", "metadata": {"id": "MCB6-dXG_Zct"}, "source": "### Escreva suas observa\u00e7\u00f5es. Aqui est\u00e3o algumas perguntas que podem ajudar: <a id='data_review_conclusions'></a>\n\n`1.   Que tipo de dados temos nas linhas? E como podemos entender as colunas?`\n\nTemos dados do tipo `object` em todas as colunas. As colunas possuem algumas incongru\u00eancias (erros no estilo), mas s\u00e3o f\u00e1ceis de entender, a n\u00e3o ser a coluna time que pode trazer confus\u00e3o (tempo escutado ou hora em que foi reproduzida?) mas dando uma olhada nos dados podemos sanar essa d\u00favida.\n\n`2.   Esses dados s\u00e3o suficientes para responder \u00e0 nossa hip\u00f3tese ou precisamos de mais dados?`\n\nDeve ser suficiente, afinal temos uma coluna para o dia da semana e uma para a cidade.\n\n`3.   Voc\u00ea notou algum problema nos dados, como valores ausentes, duplicados ou tipos de dados errados`\n\nNas colunas `'Track'`, `'artist'` e `'genre'` aparentemente temos valores ausentes, segundo o m\u00e9todo `.info()`. Para identificar valores duplicados teremos que fazer uma an\u00e1lise mais minuciosa."}, {"cell_type": "markdown", "metadata": {"id": "3eL__vcwViOi"}, "source": "[Voltar ao \u00cdndice](#back)"}, {"cell_type": "markdown", "metadata": {}, "source": "\n\n<div class=\"alert alert-success\">\n<strong>Coment\u00e1rio do revisor v1</strong>\n\nBom trabalho com a introdu\u00e7\u00e3o!\n\n</div>\n\n\n"}, {"cell_type": "markdown", "metadata": {"id": "SjYF6Ub9_Zct"}, "source": "## Etapa 2. Pr\u00e9-processamento de dados <a id='data_preprocessing'></a>\n\nO objetivo aqui \u00e9 preparar os dados para a an\u00e1lise.\nO primeiro passo \u00e9 resolver todos os problemas com o cabe\u00e7alho. E ent\u00e3o podemos passar para os valores ausentes e duplicados. Vamos come\u00e7ar.\n\nCorrija a formata\u00e7\u00e3o nos cabe\u00e7alhos da tabela.\n"}, {"cell_type": "markdown", "metadata": {"id": "dIaKXr29_Zct"}, "source": "### Estilo do cabe\u00e7alho <a id='header_style'></a>\nImprima os cabe\u00e7alhos da tabela (os nomes das colunas):"}, {"cell_type": "code", "execution_count": 7, "metadata": {"id": "oKOTdF_Q_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Index(['  userID', 'Track', 'artist', 'genre', '  City  ', 'time', 'Day'], dtype='object')\n"}], "source": "# imprima os nomes das colunas\nprint(df.columns)"}, {"cell_type": "markdown", "metadata": {"id": "zj5534cv_Zct"}, "source": "Mude os cabe\u00e7alhos da tabela conforme as boas pr\u00e1ticas de estilo:\n* Todos os caracteres precisam estar com letras min\u00fasculas\n* Exclua espa\u00e7os\n* Se o nome tiver v\u00e1rias palavras, use snake_case"}, {"cell_type": "markdown", "metadata": {"id": "Xu0zkfe5zNJe"}, "source": "Anteriormente, voc\u00ea aprendeu sobre uma maneira automatizada de renomear colunas. Vamos us\u00e1-la agora. Use o ciclo for para percorrer os nomes das colunas e transformar todos os caracteres em letras min\u00fasculas. Ap\u00f3s fazer isso, imprima os cabe\u00e7alhos da tabela novamente:"}, {"cell_type": "code", "execution_count": 8, "metadata": {"id": "6I_RwwMhzM4e", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Index(['  userid', 'track', 'artist', 'genre', '  city  ', 'time', 'day'], dtype='object')\n"}], "source": "# Percorrendo os cabe\u00e7alhos e convertendo tudo em min\u00fasculos\nlowered_columns = []\n\nfor old_name in df.columns:\n    name_lowered = old_name.lower()\n    lowered_columns.append(name_lowered)\n\ndf.columns = lowered_columns\nprint(df.columns)"}, {"cell_type": "markdown", "metadata": {"id": "pweIRxjSzPYW"}, "source": "Agora, usando a mesma abordagem, exclua os espa\u00e7os no in\u00edcio e no final de cada nome de coluna e imprima os nomes das colunas novamente:"}, {"cell_type": "code", "execution_count": 9, "metadata": {"id": "vVQXbFyJzSYl", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Index(['userid', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"}], "source": "# Percorrendo os cabe\u00e7alhos e removendo os espa\u00e7os\nstripped_columns = []\n\nfor old_name in df.columns:\n    name_stripped = old_name.strip()\n    stripped_columns.append(name_stripped)\n\ndf.columns = stripped_columns\nprint(df.columns)"}, {"cell_type": "markdown", "metadata": {"id": "yCb8MW1JzURd"}, "source": "Precisamos aplicar a regra de sublinhado no lugar de espa\u00e7o \u00e0 coluna `userid`. Deveria ser `user_id`. Renomeie essa coluna e imprima os nomes de todas as colunas quando terminar."}, {"cell_type": "code", "execution_count": 10, "metadata": {"id": "ISlFqs5y_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Index(['user_id', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"}], "source": "# Renomeando a coluna \"userid\"\ndf.rename(columns = {'userid':'user_id'}, inplace = True)\nprint(df.columns)"}, {"cell_type": "markdown", "metadata": {"id": "1dqbh00J_Zct"}, "source": "Verifique o resultado. Imprima os cabe\u00e7alhos novamente:"}, {"cell_type": "code", "execution_count": 11, "metadata": {"id": "d4NOAmTW_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Index(['user_id', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"}], "source": "# verificando o resultado: a lista de cabe\u00e7alhos\nprint(df.columns)"}, {"cell_type": "markdown", "metadata": {"id": "xYJk6ksJVpOl"}, "source": "[Voltar ao \u00cdndice](#back)"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<strong>Coment\u00e1rio do revisor v1</strong>\n\nTudo certo com o nome das colunas.\n\n</div>"}, {"cell_type": "markdown", "metadata": {"id": "5ISfbcfY_Zct"}, "source": "### Valores Ausentes <a id='missing_values'></a>\n Primeiro, encontre a quantidade de valores ausentes na tabela. Voc\u00ea precisa usar dois m\u00e9todos em sequ\u00eancia para obter o n\u00famero de valores ausentes."}, {"cell_type": "code", "execution_count": 12, "metadata": {"id": "RskX29qr_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "user_id       0\ntrack      1343\nartist     7567\ngenre      1198\ncity          0\ntime          0\nday           0\ndtype: int64\n"}], "source": "# calculando o n\u00famero de valores ausentes\nprint(df.isna().sum())"}, {"cell_type": "markdown", "metadata": {"id": "qubhgnlO_Zct"}, "source": "Nem todos os valores ausentes afetam a pesquisa. Por exemplo, os valores ausentes em `track` e `artist` n\u00e3o s\u00e3o cr\u00edticos. Voc\u00ea pode simplesmente substitu\u00ed-los por valores padr\u00e3o, como a string `'unknown'`.\n\nMas valores ausentes em `'genre'` podem afetar a compara\u00e7\u00e3o de prefer\u00eancias musicais de Springfield e Shelbyville. Na vida real, seria \u00fatil descobrir as raz\u00f5es pelas quais os dados est\u00e3o ausentes e tentar corrigi-los. Mas n\u00f3s n\u00e3o temos essa possibilidade neste projeto. Ent\u00e3o, voc\u00ea ter\u00e1 que:\n* Preencha esses valores ausentes com um valor padr\u00e3o\n* Avalie em que medida os valores ausentes podem afetar sua an\u00e1lise"}, {"cell_type": "markdown", "metadata": {"id": "fSv2laPA_Zct"}, "source": "Substitua os valores ausentes nas colunas `'track'`, `'artist'` e `'genre'` pela string `'unknown'`. Como mostramos nas li\u00e7\u00f5es anteriores, a melhor maneira de fazer isso \u00e9 criar uma lista para armazenar os nomes das colunas nas quais precisamos fazer a substitui\u00e7\u00e3o. Em seguida, use essa lista e percorra as colunas nas quais a substitui\u00e7\u00e3o seja necess\u00e1ria e fa\u00e7a a substitui\u00e7\u00e3o."}, {"cell_type": "code", "execution_count": 13, "metadata": {"id": "KplB5qWs_Zct", "trusted": true}, "outputs": [], "source": "# percorrendo os cabe\u00e7alhos e substituindo valores ausentes por 'unknown'\ncolumns_to_replace = ['track', 'artist', 'genre']\nfor col in columns_to_replace:\n    df[col].fillna('unknown', inplace = True)"}, {"cell_type": "markdown", "metadata": {"id": "Ilsm-MZo_Zct"}, "source": "Agora verifique o resultado para ter certeza de que o conjunto de dados n\u00e3o contenha valores ausentes ap\u00f3s a substitui\u00e7\u00e3o. Para fazer isso, conte os valores ausentes novamente."}, {"cell_type": "code", "execution_count": 14, "metadata": {"id": "Tq4nYRX4_Zct", "scrolled": true, "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "user_id    0\ntrack      0\nartist     0\ngenre      0\ncity       0\ntime       0\nday        0\ndtype: int64\n"}], "source": "# contando os valores ausentes\nprint(df.isna().sum())"}, {"cell_type": "markdown", "metadata": {"id": "74ZIBmq9VrsK"}, "source": "[Voltar ao \u00cdndice](#back)"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<strong>Coment\u00e1rio do revisor v1</strong>\n\nValores ausentes tratados com sucesso!\n\n</div>\n"}, {"cell_type": "markdown", "metadata": {"id": "BWKRtBJ3_Zct"}, "source": "### Duplicados <a id='duplicates'></a>\nEncontre o n\u00famero de duplicados expl\u00edcitos na tabela. Lembre-se de que voc\u00ea precisa aplicar dois m\u00e9todos em sequ\u00eancia para obter o n\u00famero de duplicados expl\u00edcitos."}, {"cell_type": "code", "execution_count": 15, "metadata": {"id": "36eES_S0_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "3826\n"}], "source": "# contando duplicados expl\u00edcitos\nprint(df.duplicated().sum())"}, {"cell_type": "markdown", "metadata": {"id": "Ot25h6XR_Zct"}, "source": "Agora descarte todos os duplicados. Para fazer isso, chame o m\u00e9todo que faz exatamente isso."}, {"cell_type": "code", "execution_count": 22, "metadata": {"id": "exFHq6tt_Zct", "scrolled": true, "trusted": true}, "outputs": [], "source": "# removendo duplicados expl\u00edcitos\n# redefinindo os ind\u00edces\ndf = df.drop_duplicates().reset_index(drop = True)"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-danger\">\n<strong>Coment\u00e1rio do revisor v1</strong>\n\nAqui vale a pena utilizar o .reset_index(drop=True) para garantir que n\u00e3o teremos problemas com a ordem das observa\u00e7\u00f5es ap\u00f3s removermos os duplicados:\n    \nAo remover duplicatas, o \u00edndice do DataFrame pode ficar desorganizado. Isso significa que voc\u00ea pode acabar com lacunas no \u00edndice ou com \u00edndices que n\u00e3o est\u00e3o mais em ordem sequencial. O m\u00e9todo reset_index() redefine o \u00edndice do DataFrame, garantindo que ele esteja organizado novamente em uma sequ\u00eancia num\u00e9rica cont\u00ednua.\n</div>\n\n"}, {"cell_type": "markdown", "metadata": {}, "source": "\n<div class=\"alert alert-success\">\n<strong>Coment\u00e1rio do revisor v2</strong>\n\nValeu pelo ajuste!\n</div>"}, {"cell_type": "markdown", "metadata": {"id": "Im2YwBEG_Zct"}, "source": "Agora vamos verificar se descartamos todos os duplicados. Conte duplicados expl\u00edcitos mais uma vez para ter certeza de que voc\u00ea removeu todos eles:"}, {"cell_type": "code", "execution_count": 23, "metadata": {"id": "-8PuNWQ0_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "0\n"}], "source": "# verificando duplicados novamente\nprint(df.duplicated().sum())"}, {"cell_type": "markdown", "metadata": {"id": "QlFBsxAr_Zct"}, "source": "Agora queremos nos livrar dos duplicados impl\u00edcitos na coluna `genre`. Por exemplo, o nome de um g\u00eanero pode ser escrito de maneiras diferentes. Alguns erros afetar\u00e3o tamb\u00e9m o resultado."}, {"cell_type": "markdown", "metadata": {"id": "eSjWwsOh_Zct"}, "source": "Para fazer isso, vamos come\u00e7ar imprimindo uma lista de nomes de g\u00eanero \u00fanicos, ordenados em ordem alfab\u00e9tica: Para fazer isso:\n* Extraia a coluna `genre` do DataFrame\n* Chame o m\u00e9todo que retornar\u00e1 todos os valores \u00fanicos na coluna extra\u00edda\n"}, {"cell_type": "code", "execution_count": 24, "metadata": {"id": "JIUcqzZN_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "['rock' 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic'\n 'unknown' 'alternative' 'children' 'rnb' 'hip' 'jazz' 'postrock' 'latin'\n 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental' 'rusrock'\n 'dnb' 't\u00fcrk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n 'disco' 'religious' 'hiphop' 'drum' 'extrememetal' 't\u00fcrk\u00e7e'\n 'experimental' 'easy' 'metalcore' 'modern' 'argentinetango' 'old' 'swing'\n 'breaks' 'eurofolk' 'stonerrock' 'industrial' 'funk' 'middle' 'vari\u00e9t\u00e9'\n 'other' 'adult' 'christian' 'thrash' 'gothic' 'international' 'muslim'\n 'relax' 'schlager' 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage'\n 'specialty' 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power'\n 'death' 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european'\n 'tech' 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera'\n 'celtic' 'tradjazz' 'acoustic' 'epicmetal' 'hip-hop' 'historisch'\n 'downbeat' 'downtempo' 'africa' 'audiobook' 'jewish' 's\u00e4ngerportrait'\n 'deutschrock' 'eastern' 'action' 'future' 'electropop' 'folklore'\n 'bollywood' 'marschmusik' 'rnr' 'karaoke' 'indian' 'rancheras'\n 'afrikaans' 'rhythm' 'sound' 'deutschspr' 'trip' 'lovers' 'choral'\n 'dancepop' 'retro' 'smooth' 'mexican' 'brazilian' '\u00ef\u00ee\u00ef' 'mood' 'surf'\n 'gangsta' 'inspirational' 'idm' 'ethnic' 'bluegrass' 'broadway'\n 'animated' 'americana' 'karadeniz' 'rockabilly' 'colombian' 'self' 'hop'\n 'sertanejo' 'japanese' 'canzone' 'lounge' 'sport' 'ragga' 'traditional'\n 'gitarre' 'frankreich' 'emo' 'laiko' 'cantopop' 'glitch' 'documentary'\n 'oceania' 'popeurodance' 'dark' 'vi' 'grunge' 'hardstyle' 'samba'\n 'garage' 'art' 'folktronica' 'entehno' 'mediterranean' 'chamber' 'cuban'\n 'taraftar' 'gypsy' 'hardtechno' 'shoegazing' 'bossa' 'latino' 'worldbeat'\n 'malaysian' 'baile' 'ghazal' 'arabic' 'popelectronic' 'acid' 'kayokyoku'\n 'neoklassik' 'tribal' 'tanzorchester' 'native' 'independent' 'cantautori'\n 'handsup' 'punjabi' 'synthpop' 'rave' 'franz\u00f6sisch' 'quebecois' 'speech'\n 'soulful' 'jam' 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow'\n 'jungle' 'indipop' 'ax\u00e9' 'fado' 'showtunes' 'arena' 'irish' 'mandopop'\n 'forr\u00f3' 'dirty' 'regional']\n"}], "source": "# visualizando nomes de g\u00eaneros \u00fanicos\nprint(df['genre'].unique())"}, {"cell_type": "markdown", "metadata": {"id": "qej-Qmuo_Zct"}, "source": "Olhe a lista e encontre duplicados impl\u00edcitos do g\u00eanero `hiphop`. Esses podem ser nomes escritos incorretamente, ou nomes alternativos para o mesmo g\u00eanero.\n\nVoc\u00ea ver\u00e1 os seguintes duplicados impl\u00edcitos:\n* `hip`\n* `hop`\n* `hip-hop`\n\nPara se livrar deles, crie uma fun\u00e7\u00e3o `replace_wrong_genres()` com dois par\u00e2metros:\n* `wrong_genres=` \u2014 essa \u00e9 uma lista que cont\u00e9m todos os valores que voc\u00ea precisa substituir\n* `correct_genre=` \u2014 essa \u00e9 uma string que voc\u00ea vai usar para a substitui\u00e7\u00e3o\n\nComo resultado, a fun\u00e7\u00e3o deve corrigir os nomes na coluna `'genre'` da tabela `df`, isto \u00e9, substituindo cada valor da lista `wrong_genres` por valores de `correct_genre`.\n\nDentro do corpo da fun\u00e7\u00e3o, use um ciclo `'for'` para percorrer a lista de g\u00eaneros errados, extrair a coluna `'genre'` e aplicar o m\u00e9todo `replace` para fazer as corre\u00e7\u00f5es."}, {"cell_type": "code", "execution_count": 22, "metadata": {"id": "ErNDkmns_Zct", "trusted": true}, "outputs": [], "source": "# fun\u00e7\u00e3o para substituir duplicados impl\u00edcitos\ndef replace_wrong_genres(wrong_genres, correct_genre):\n    for wrong_genre in wrong_genres:\n        df['genre'].replace(wrong_genre, correct_genre, inplace = True)\n    return df"}, {"cell_type": "raw", "metadata": {"id": "aDoBJxbA_Zct"}, "source": "Agora, chame a fun\u00e7\u00e3o `replace_wrong_genres()` e passe argumentos apropriados para que ela limpe duplicados impl\u00edcitos (`hip`, `hop` e `hip-hop`) substituindo-os por `hiphop`:"}, {"cell_type": "code", "execution_count": 23, "metadata": {"id": "YN5i2hpmSo09", "trusted": true}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>track</th>\n      <th>artist</th>\n      <th>genre</th>\n      <th>city</th>\n      <th>time</th>\n      <th>day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FFB692EC</td>\n      <td>Kamigata To Boots</td>\n      <td>The Mass Missile</td>\n      <td>rock</td>\n      <td>Shelbyville</td>\n      <td>20:28:33</td>\n      <td>Wednesday</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55204538</td>\n      <td>Delayed Because of Accident</td>\n      <td>Andreas R\u00f6nnberg</td>\n      <td>rock</td>\n      <td>Springfield</td>\n      <td>14:07:09</td>\n      <td>Friday</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20EC38</td>\n      <td>Funicul\u00ec funicul\u00e0</td>\n      <td>Mario Lanza</td>\n      <td>pop</td>\n      <td>Shelbyville</td>\n      <td>20:58:07</td>\n      <td>Wednesday</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A3DD03C9</td>\n      <td>Dragons in the Sunset</td>\n      <td>Fire + Ice</td>\n      <td>folk</td>\n      <td>Shelbyville</td>\n      <td>08:37:09</td>\n      <td>Monday</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>E2DC1FAE</td>\n      <td>Soul People</td>\n      <td>Space Echo</td>\n      <td>dance</td>\n      <td>Springfield</td>\n      <td>08:34:34</td>\n      <td>Monday</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>65074</th>\n      <td>729CBB09</td>\n      <td>My Name</td>\n      <td>McLean</td>\n      <td>rnb</td>\n      <td>Springfield</td>\n      <td>13:32:28</td>\n      <td>Wednesday</td>\n    </tr>\n    <tr>\n      <th>65075</th>\n      <td>D08D4A55</td>\n      <td>Maybe One Day (feat. Black Spade)</td>\n      <td>Blu &amp; Exile</td>\n      <td>hiphop</td>\n      <td>Shelbyville</td>\n      <td>10:00:00</td>\n      <td>Monday</td>\n    </tr>\n    <tr>\n      <th>65076</th>\n      <td>C5E3A0D5</td>\n      <td>Jalopiina</td>\n      <td>unknown</td>\n      <td>industrial</td>\n      <td>Springfield</td>\n      <td>20:09:26</td>\n      <td>Friday</td>\n    </tr>\n    <tr>\n      <th>65077</th>\n      <td>321D0506</td>\n      <td>Freight Train</td>\n      <td>Chas McDevitt</td>\n      <td>rock</td>\n      <td>Springfield</td>\n      <td>21:43:59</td>\n      <td>Friday</td>\n    </tr>\n    <tr>\n      <th>65078</th>\n      <td>3A64EF84</td>\n      <td>Tell Me Sweet Little Lies</td>\n      <td>Monica Lopez</td>\n      <td>country</td>\n      <td>Springfield</td>\n      <td>21:59:46</td>\n      <td>Friday</td>\n    </tr>\n  </tbody>\n</table>\n<p>61253 rows \u00d7 7 columns</p>\n</div>", "text/plain": "        user_id                              track            artist  \\\n0      FFB692EC                  Kamigata To Boots  The Mass Missile   \n1      55204538        Delayed Because of Accident  Andreas R\u00f6nnberg   \n2        20EC38                  Funicul\u00ec funicul\u00e0       Mario Lanza   \n3      A3DD03C9              Dragons in the Sunset        Fire + Ice   \n4      E2DC1FAE                        Soul People        Space Echo   \n...         ...                                ...               ...   \n65074  729CBB09                            My Name            McLean   \n65075  D08D4A55  Maybe One Day (feat. Black Spade)       Blu & Exile   \n65076  C5E3A0D5                          Jalopiina           unknown   \n65077  321D0506                      Freight Train     Chas McDevitt   \n65078  3A64EF84          Tell Me Sweet Little Lies      Monica Lopez   \n\n            genre         city      time        day  \n0            rock  Shelbyville  20:28:33  Wednesday  \n1            rock  Springfield  14:07:09     Friday  \n2             pop  Shelbyville  20:58:07  Wednesday  \n3            folk  Shelbyville  08:37:09     Monday  \n4           dance  Springfield  08:34:34     Monday  \n...           ...          ...       ...        ...  \n65074         rnb  Springfield  13:32:28  Wednesday  \n65075      hiphop  Shelbyville  10:00:00     Monday  \n65076  industrial  Springfield  20:09:26     Friday  \n65077        rock  Springfield  21:43:59     Friday  \n65078     country  Springfield  21:59:46     Friday  \n\n[61253 rows x 7 columns]"}, "execution_count": 23, "metadata": {}, "output_type": "execute_result"}], "source": "# removendo duplicados impl\u00edcitos\nreplace_wrong_genres(['hip', 'hop', 'hip-hop'], 'hiphop')"}, {"cell_type": "markdown", "metadata": {"id": "zQKF16_RG15m"}, "source": "Certifique-se que os nomes duplicados foram removidos. Imprima a lista de valores \u00fanicos da coluna `'genre'` mais uma vez:"}, {"cell_type": "code", "execution_count": 24, "metadata": {"id": "wvixALnFG15m", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "['rock' 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic'\n 'unknown' 'alternative' 'children' 'rnb' 'hiphop' 'jazz' 'postrock'\n 'latin' 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental'\n 'rusrock' 'dnb' 't\u00fcrk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n 'disco' 'religious' 'drum' 'extrememetal' 't\u00fcrk\u00e7e' 'experimental' 'easy'\n 'metalcore' 'modern' 'argentinetango' 'old' 'swing' 'breaks' 'eurofolk'\n 'stonerrock' 'industrial' 'funk' 'middle' 'vari\u00e9t\u00e9' 'other' 'adult'\n 'christian' 'thrash' 'gothic' 'international' 'muslim' 'relax' 'schlager'\n 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage' 'specialty'\n 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power' 'death'\n 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european' 'tech'\n 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera' 'celtic'\n 'tradjazz' 'acoustic' 'epicmetal' 'historisch' 'downbeat' 'downtempo'\n 'africa' 'audiobook' 'jewish' 's\u00e4ngerportrait' 'deutschrock' 'eastern'\n 'action' 'future' 'electropop' 'folklore' 'bollywood' 'marschmusik' 'rnr'\n 'karaoke' 'indian' 'rancheras' 'afrikaans' 'rhythm' 'sound' 'deutschspr'\n 'trip' 'lovers' 'choral' 'dancepop' 'retro' 'smooth' 'mexican'\n 'brazilian' '\u00ef\u00ee\u00ef' 'mood' 'surf' 'gangsta' 'inspirational' 'idm' 'ethnic'\n 'bluegrass' 'broadway' 'animated' 'americana' 'karadeniz' 'rockabilly'\n 'colombian' 'self' 'sertanejo' 'japanese' 'canzone' 'lounge' 'sport'\n 'ragga' 'traditional' 'gitarre' 'frankreich' 'emo' 'laiko' 'cantopop'\n 'glitch' 'documentary' 'oceania' 'popeurodance' 'dark' 'vi' 'grunge'\n 'hardstyle' 'samba' 'garage' 'art' 'folktronica' 'entehno'\n 'mediterranean' 'chamber' 'cuban' 'taraftar' 'gypsy' 'hardtechno'\n 'shoegazing' 'bossa' 'latino' 'worldbeat' 'malaysian' 'baile' 'ghazal'\n 'arabic' 'popelectronic' 'acid' 'kayokyoku' 'neoklassik' 'tribal'\n 'tanzorchester' 'native' 'independent' 'cantautori' 'handsup' 'punjabi'\n 'synthpop' 'rave' 'franz\u00f6sisch' 'quebecois' 'speech' 'soulful' 'jam'\n 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow' 'jungle' 'indipop'\n 'ax\u00e9' 'fado' 'showtunes' 'arena' 'irish' 'mandopop' 'forr\u00f3' 'dirty'\n 'regional']\n"}], "source": "# verificando valores duplicados\nprint(df['genre'].unique())"}, {"cell_type": "markdown", "metadata": {"id": "ALgNbvF3VtPA"}, "source": "[Voltar ao \u00cdndice](#back)"}, {"cell_type": "markdown", "metadata": {"id": "jz6a9-7HQUDd"}, "source": "### Suas observa\u00e7\u00f5es <a id='data_preprocessing_conclusions'></a>\n\n` Descreva brevemente o que voc\u00ea reparou ao analisar duplicados, bem como a abordagem que usou para elimin\u00e1-los e os resultados que alcan\u00e7ou.`\n\nUtilizei o m\u00e9todo `.duplicated()` junto com o m\u00e9todo `.sum()` para encontrar o n\u00ba de valores duplicados. Com a ajudinha do enunciado e do `CTRL + F` encontrei valores duplicados de `hiphop`, mas fiquei me perguntando como eu faria no futuro se o enunciado n\u00e3o tivesse me ajudado com os valores duplicados. Espero que nos pr\u00f3ximos sprints seja apresentada alguma ferramenta que possa me ajudar em situa\u00e7\u00f5es assim. Ap\u00f3s encontrar os valores duplicados, utilizei uma fun\u00e7\u00e3o para substituir os duplicados de `hiphop`, e ent\u00e3o finalizei o pr\u00e9-processamento do meu DataFrame, renomeando as colunas, substituindo os valores ausentes e removendo linhas duplicadas, assim como substituindo valores duplicados."}, {"cell_type": "markdown", "metadata": {"id": "eK1es74rVujj"}, "source": "[Voltar ao \u00cdndice](#back)"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<strong>Coment\u00e1rio do revisor v1</strong>\n\nBom trabalho com os duplicados impl\u00edcitos e expl\u00edcitos\n</div>\n"}, {"cell_type": "markdown", "metadata": {"id": "WttZHXH0SqKk"}, "source": "## Etapa 3. Teste da hip\u00f3tese <a id='hypothesis'></a>"}, {"cell_type": "markdown", "metadata": {"id": "Im936VVi_Zcu"}, "source": "### Hip\u00f3tese: compara\u00e7\u00e3o do comportamento dos usu\u00e1rios nas duas cidades <a id='activity'></a>"}, {"cell_type": "markdown", "metadata": {"id": "nwt_MuaL_Zcu"}, "source": "A hip\u00f3tese afirma que existem diferen\u00e7as no consumo de m\u00fasica pelos usu\u00e1rios em Springfield e em Shelbyville. Para testar a hip\u00f3tese, use os dados dos tr\u00eas dias da semana: segunda-feira (Monday), quarta-feira (Wednesday) e sexta-feira (Friday).\n\n* Agrupe os usu\u00e1rios por cidade.\n* Compare o n\u00famero de m\u00fasicas tocadas por cada grupo na segunda, quarta e sexta.\n"}, {"cell_type": "markdown", "metadata": {"id": "8Dw_YMmT_Zcu"}, "source": "Execute cada c\u00e1lculo separadamente.\n\nO primeiro passo \u00e9 avaliar a atividade dos usu\u00e1rios em cada cidade. N\u00e3o se esque\u00e7a das etapas \"divis\u00e3o-aplica\u00e7\u00e3o-combina\u00e7\u00e3o\" sobre as quais falamos anteriormente na li\u00e7\u00e3o. Agora seu objetivo \u00e9 agrupar os dados por cidade, aplicar o m\u00e9todo de contagem apropriado durante a etapa de aplica\u00e7\u00e3o e ent\u00e3o encontrar o n\u00famero de m\u00fasicas tocadas por cada grupo, especificando a coluna para a qual voc\u00ea quer obter a contagem.\n\nVeja um exemplo de como o resultado final deve ser:\n`df.groupby(by='....')['column'].method()` Execute cada c\u00e1lculo separadamente.\n\nPara avaliar a atividade dos usu\u00e1rios em cada cidade, agrupe os dados por cidade e encontre o n\u00famero de m\u00fasicas reproduzidas em cada grupo.\n\n"}, {"cell_type": "code", "execution_count": 25, "metadata": {"id": "0_Qs96oh_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "             user_id  track  artist  genre   time    day\ncity                                                    \nShelbyville    18512  18512   18512  18512  18512  18512\nSpringfield    42741  42741   42741  42741  42741  42741\n"}], "source": "# Contando as m\u00fasicas tocadas em cada cidade\nmusic_by_city = df.groupby('city').count()\nprint(music_by_city)"}, {"cell_type": "markdown", "metadata": {"id": "t_Qx-3NewAnK"}, "source": "`Comente sobre suas observa\u00e7\u00f5es aqui`\n\nSpringfield tem mais do dobro de m\u00fasicas tocadas do que Shelbyville."}, {"cell_type": "markdown", "metadata": {"id": "dzli3w8o_Zcu"}, "source": "Agora vamos agrupar os dados por dia da semana e encontrar a quantidade de m\u00fasicas tocadas na segunda, quarta e sexta-feira. Use a mesma abordagem que antes, mas agora precisamos agrupar os dados de uma forma diferente.\n"}, {"cell_type": "code", "execution_count": 26, "metadata": {"id": "uZMKjiJz_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "           user_id  track  artist  genre   city   time\nday                                                   \nFriday       21840  21840   21840  21840  21840  21840\nMonday       21354  21354   21354  21354  21354  21354\nWednesday    18059  18059   18059  18059  18059  18059\n"}], "source": "# Calculando as m\u00fasicas escutadas em cada um desses tr\u00eas dias\nmusic_by_day = df.groupby('day').count()\nprint(music_by_day)"}, {"cell_type": "markdown", "metadata": {"id": "cC2tNrlL_Zcu"}, "source": "`Comente sobre suas observa\u00e7\u00f5es aqui`\n\nSexta-feira \u00e9 o dia com mais m\u00fasicas escutadas, seguida por segunda-feira e por fim quarta-feira."}, {"cell_type": "markdown", "metadata": {"id": "POzs8bGa_Zcu"}, "source": "Voc\u00ea acabou de aprender como contar entradas agrupando-as por cidade ou por dia. E agora voc\u00ea precisa escrever uma fun\u00e7\u00e3o que possa contar entradas simultaneamente com base em ambos os crit\u00e9rios.\n\nCrie a fun\u00e7\u00e3o `number_tracks()` para calcular o n\u00famero de m\u00fasicas tocadas em um determinado dia **e** em uma determinada cidade. A fun\u00e7\u00e3o deve aceitar dois par\u00e2metros:\n\n- `day`: um dia da semana pelo qual precisamos filtrar os dados. Por exemplo, `'Monday'`.\n- `city`: uma cidade pela qual precisamos filtrar os dados. Por exemplo, `'Springfield'`.\n\nDentro da fun\u00e7\u00e3o, voc\u00ea vai aplicar uma filtragem consecutiva com indexa\u00e7\u00e3o l\u00f3gica.\n\nPrimeiro, filtre os dados por dia e ent\u00e3o filtre a tabela resultante por cidade.\n\nDepois de filtrar os dados usando os dois crit\u00e9rios, conte o n\u00famero de valores na coluna 'user_id' da tabela resultante. O resultado da contagem representar\u00e1 o n\u00famero de entradas que voc\u00ea quer encontrar. Armazene o resultado em uma nova vari\u00e1vel e imprima-o."}, {"cell_type": "code", "execution_count": 27, "metadata": {"id": "Nz3GdQB1_Zcu", "trusted": true}, "outputs": [], "source": "# Declare a fun\u00e7\u00e3o number_tracks() com dois par\u00e2metros: day= e city=.\n\n    # Armazene as linhas do DataFrame em que o valor na coluna 'day' \u00e9 igual ao par\u00e2metro day=\n\n    # Filtre as linhas em que o valor na coluna 'city' \u00e9 igual ao par\u00e2metro city=\n\n    # Extraia a coluna 'user_id' da tabela filtrada e aplique o m\u00e9todo count()\n\n    # Retorne o n\u00famero dos valores da coluna 'user_id'\ndef number_tracks(day, city):\n    track_day = df[df['day'] == day]\n    track_day_city = track_day[track_day['city'] == city]\n    return track_day_city['user_id'].count()"}, {"cell_type": "markdown", "metadata": {"id": "ytf7xFrFJQ2r"}, "source": "Chame a fun\u00e7\u00e3o `number_tracks()` seis vezes, mudando os valores dos par\u00e2metros, para que voc\u00ea possa recuperar os dados de ambas as cidades para cada um dos tr\u00eas dias."}, {"cell_type": "code", "execution_count": 28, "metadata": {"id": "rJcRATNQ_Zcu", "trusted": true}, "outputs": [{"data": {"text/plain": "15740"}, "execution_count": 28, "metadata": {}, "output_type": "execute_result"}], "source": "# a quantidade de m\u00fasicas tocadas em Springfield na segunda-feira\nnumber_tracks('Monday', 'Springfield')"}, {"cell_type": "code", "execution_count": 29, "metadata": {"id": "hq_ncZ5T_Zcu", "trusted": true}, "outputs": [{"data": {"text/plain": "5614"}, "execution_count": 29, "metadata": {}, "output_type": "execute_result"}], "source": "# a quantidade de m\u00fasicas tocadas em Shelbyville na segunda-feira\nnumber_tracks('Monday', 'Shelbyville')"}, {"cell_type": "code", "execution_count": 30, "metadata": {"id": "_NTy2VPU_Zcu", "trusted": true}, "outputs": [{"data": {"text/plain": "11056"}, "execution_count": 30, "metadata": {}, "output_type": "execute_result"}], "source": "# a quantidade de m\u00fasicas tocadas em Springfield na quarta-feira\nnumber_tracks('Wednesday', 'Springfield')"}, {"cell_type": "code", "execution_count": 31, "metadata": {"id": "j2y3TAwo_Zcu", "trusted": true}, "outputs": [{"data": {"text/plain": "7003"}, "execution_count": 31, "metadata": {}, "output_type": "execute_result"}], "source": "# a quantidade de m\u00fasicas tocadas em Shelbyville na quarta-feira\nnumber_tracks('Wednesday', 'Shelbyville')"}, {"cell_type": "code", "execution_count": 32, "metadata": {"id": "vYDw5u_K_Zcu", "trusted": true}, "outputs": [{"data": {"text/plain": "15945"}, "execution_count": 32, "metadata": {}, "output_type": "execute_result"}], "source": "# a quantidade de m\u00fasicas tocadas em Springfield na sexta-feira\nnumber_tracks('Friday', 'Springfield')"}, {"cell_type": "code", "execution_count": 33, "metadata": {"id": "8_yzFtW3_Zcu", "trusted": true}, "outputs": [{"data": {"text/plain": "5895"}, "execution_count": 33, "metadata": {}, "output_type": "execute_result"}], "source": "# a quantidade de m\u00fasicas tocadas em Shelbyville na sexta-feira\nnumber_tracks('Friday', 'Shelbyville')"}, {"cell_type": "markdown", "metadata": {}, "source": "\n<div class=\"alert alert-success\">\n<strong>Coment\u00e1rio do revisor v1</strong>\n\nA fun\u00e7\u00e3o solicitada foi desenvolvida e o c\u00e1lculo das reprodu\u00e7\u00f5es foi realizado com sucesso.\n</div>"}, {"cell_type": "markdown", "metadata": {"id": "-EgPIHYu_Zcu"}, "source": "**Conclus\u00f5es**\n\n`Comente sobre se a terceira hip\u00f3tese est\u00e1 correta ou deve ser rejeitada. Explique seu racioc\u00ednio.`\n\nVamos novamente \u00e0 hip\u00f3tese: `'A atividade dos usu\u00e1rios \u00e9 diferente dependendo do dia da semana e da cidade.'`. De acordo com meus levantamentos, de fato a atividade dos usu\u00e1rios muda a depender do dia da semana e da cidade. Na segunda-feira, vemos `15740` m\u00fasicas tocadas em Springfield, enquanto apenas `5614` m\u00fasicas tocadas em Shelbyville. Infelizmente n\u00e3o possu\u00edmos o n\u00ba de habitantes de cada cidade para fazer uma an\u00e1lise mais precisa sobre a propor\u00e7\u00e3o de habitantes e de usu\u00e1rios em cada cidade, mas com os dados que temos podemos assumir que h\u00e1 mais usu\u00e1rios em Springfield. Na quarta-feira, em Springfield, vemos uma redu\u00e7\u00e3o de 29.76% em rela\u00e7\u00e3o \u00e0 segunda-feira, com `11056` m\u00fasicas escutadas. J\u00e1 em Shelbyville, vemos um aumento de 24.74% nas m\u00fasicas escutadas, passando de `5614` para `7003` streams. Na sexta-feira, o n\u00ba de m\u00fasicas escutadas atinge seu pico em Springfield, com `15945` streams, um aumento de 44.22% em rela\u00e7\u00e3o \u00e0 quarta-feira, mas apenas um aumento de 1.3% em rela\u00e7\u00e3o \u00e0 segunda-feira. Em Shelbyville, o n\u00ba de m\u00fasicas escutadas cai de `7003` na quarta-feira para `5895` na sexta-feira, representando uma redu\u00e7\u00e3o de 15.82%, enquanto a diferen\u00e7a de segunda-feira para a sexta-feira \u00e9 de apenas 5%. Como podemos observar, a atividade dos usu\u00e1rios \u00e9 bem similar na segunda-feira e na sexta-feira, apenas havendo uma mudan\u00e7a significativa na quarta-feira, onde em Springfield o n\u00ba de m\u00fasicas escutadas diminui e em Shelbyville o n\u00ba de m\u00fasicas escutadas aumenta."}, {"cell_type": "markdown", "metadata": {"id": "p7nFQajCVw5B"}, "source": "[Voltar ao \u00cdndice](#back)"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<strong>Coment\u00e1rio do revisor v1</strong>\n\nA hip\u00f3tese foi avaliada com sucesso e argumentos robustos foram apresentados justificando a conclus\u00e3o.\n</div>\n"}, {"cell_type": "markdown", "metadata": {"id": "ykKQ0N65_Zcv"}, "source": "# Conclus\u00f5es <a id='end'></a>"}, {"cell_type": "markdown", "metadata": {"id": "tjUwbHb3_Zcv"}, "source": "`Resuma suas conclus\u00f5es sobre a hip\u00f3tese aqui`\n\nAp\u00f3s observar a an\u00e1lise, podemos concluir que nossa hip\u00f3tese est\u00e1 correta. O n\u00ba de m\u00fasicas escutadas varia sim dependendo do dia da semana e da cidade. Em Springfield temos um n\u00ba de streams de `15740` na segunda, descendo para `11056` na quarta e subindo para `15945` na sexta. J\u00e1 em Shelbyville, temos `5614` m\u00fasicas escutadas na segunda, `7003` na quarta e `5895` na sexta. Como podemos observar em Springfield, o n\u00ba de m\u00fasicas escutadas \u00e9 menor na quarta-feira, enquanto em Shelbyville esse mesmo n\u00ba aumenta, o que confirma nossa hip\u00f3tese."}, {"cell_type": "markdown", "metadata": {"id": "azLHu64yOIp7"}, "source": "### Importante\nEm projetos de pesquisas reais, o teste estat\u00edstico de hip\u00f3teses \u00e9 mais preciso e quantitativo. Observe tamb\u00e9m que conclus\u00f5es sobre uma cidade inteira nem sempre podem ser tiradas a partir de dados de apenas uma fonte.\n\nVoc\u00ea aprender\u00e1 mais sobre testes de hip\u00f3teses no sprint sobre a an\u00e1lise estat\u00edstica de dados."}, {"cell_type": "markdown", "metadata": {"id": "Ju4AHDSgV1FE"}, "source": "[Voltar ao \u00cdndice](#back)"}], "metadata": {"ExecuteTimeLog": [{"duration": 218, "start_time": "2025-05-05T19:06:21.768Z"}, {"duration": 289, "start_time": "2025-05-05T19:06:44.973Z"}, {"duration": 362, "start_time": "2025-05-05T19:06:47.236Z"}, {"duration": 107, "start_time": "2025-05-05T19:06:58.987Z"}, {"duration": 7, "start_time": "2025-05-05T19:07:02.123Z"}, {"duration": 23, "start_time": "2025-05-05T20:42:20.972Z"}, {"duration": 6, "start_time": "2025-05-05T20:42:30.541Z"}, {"duration": 28, "start_time": "2025-05-05T20:43:26.028Z"}, {"duration": 3, "start_time": "2025-05-05T21:06:56.858Z"}, {"duration": 14, "start_time": "2025-05-05T21:10:43.083Z"}, {"duration": 3, "start_time": "2025-05-05T21:10:53.347Z"}, {"duration": 4, "start_time": "2025-05-05T21:12:07.359Z"}, {"duration": 4, "start_time": "2025-05-05T21:13:01.175Z"}, {"duration": 14, "start_time": "2025-05-05T21:15:05.240Z"}, {"duration": 14, "start_time": "2025-05-05T21:15:15.216Z"}, {"duration": 4, "start_time": "2025-05-05T21:15:41.212Z"}, {"duration": 19, "start_time": "2025-05-05T21:17:20.398Z"}, {"duration": 9, "start_time": "2025-05-05T21:18:06.778Z"}, {"duration": 4, "start_time": "2025-05-05T21:18:26.023Z"}, {"duration": 3, "start_time": "2025-05-05T21:18:59.392Z"}, {"duration": 17, "start_time": "2025-05-05T21:19:38.595Z"}, {"duration": 17, "start_time": "2025-05-05T21:24:24.399Z"}, {"duration": 10, "start_time": "2025-05-05T21:24:41.448Z"}, {"duration": 16, "start_time": "2025-05-05T21:24:43.470Z"}, {"duration": 41, "start_time": "2025-05-05T21:25:40.283Z"}, {"duration": 43, "start_time": "2025-05-05T21:26:11.318Z"}, {"duration": 62, "start_time": "2025-05-05T21:26:14.835Z"}, {"duration": 38, "start_time": "2025-05-05T21:26:16.523Z"}, {"duration": 8, "start_time": "2025-05-05T21:27:23.748Z"}, {"duration": 7, "start_time": "2025-05-05T23:06:13.648Z"}, {"duration": 3, "start_time": "2025-05-05T23:08:01.544Z"}, {"duration": 16, "start_time": "2025-05-05T23:09:12.443Z"}, {"duration": 6, "start_time": "2025-05-05T23:09:25.159Z"}, {"duration": 420, "start_time": "2025-05-06T00:29:06.851Z"}, {"duration": 18, "start_time": "2025-05-06T00:29:25.731Z"}, {"duration": 427, "start_time": "2025-05-06T00:29:46.472Z"}, {"duration": 330, "start_time": "2025-05-06T00:29:49.150Z"}, {"duration": 22, "start_time": "2025-05-06T04:15:22.902Z"}, {"duration": 22, "start_time": "2025-05-06T04:18:35.748Z"}, {"duration": 20, "start_time": "2025-05-06T04:19:34.475Z"}, {"duration": 6, "start_time": "2025-05-06T23:56:18.307Z"}, {"duration": 163, "start_time": "2025-05-06T23:57:18.708Z"}, {"duration": 275, "start_time": "2025-05-06T23:57:55.954Z"}, {"duration": 107, "start_time": "2025-05-06T23:57:57.487Z"}, {"duration": 435, "start_time": "2025-05-06T23:58:06.302Z"}, {"duration": 2, "start_time": "2025-05-07T00:05:26.601Z"}, {"duration": 90, "start_time": "2025-05-07T00:05:27.896Z"}, {"duration": 6, "start_time": "2025-05-07T00:05:29.107Z"}, {"duration": 21, "start_time": "2025-05-07T00:05:32.272Z"}, {"duration": 4, "start_time": "2025-05-07T00:05:36.276Z"}, {"duration": 4, "start_time": "2025-05-07T00:05:38.651Z"}, {"duration": 3, "start_time": "2025-05-07T00:05:40.954Z"}, {"duration": 4, "start_time": "2025-05-07T00:05:42.747Z"}, {"duration": 3, "start_time": "2025-05-07T00:05:45.048Z"}, {"duration": 18, "start_time": "2025-05-07T00:05:47.289Z"}, {"duration": 14, "start_time": "2025-05-07T00:05:49.681Z"}, {"duration": 18, "start_time": "2025-05-07T00:05:51.787Z"}, {"duration": 45, "start_time": "2025-05-07T00:05:54.059Z"}, {"duration": 72, "start_time": "2025-05-07T00:05:56.030Z"}, {"duration": 42, "start_time": "2025-05-07T00:05:57.671Z"}, {"duration": 5, "start_time": "2025-05-07T00:06:00.047Z"}, {"duration": 3, "start_time": "2025-05-07T00:06:03.189Z"}, {"duration": 24, "start_time": "2025-05-07T00:06:04.906Z"}, {"duration": 6, "start_time": "2025-05-07T00:06:08.071Z"}, {"duration": 21, "start_time": "2025-05-07T00:06:12.372Z"}, {"duration": 20, "start_time": "2025-05-07T00:06:14.638Z"}, {"duration": 3, "start_time": "2025-05-07T00:06:17.811Z"}, {"duration": 14, "start_time": "2025-05-07T00:06:21.472Z"}, {"duration": 13, "start_time": "2025-05-07T00:06:55.812Z"}, {"duration": 12, "start_time": "2025-05-07T00:07:35.692Z"}, {"duration": 12, "start_time": "2025-05-07T00:08:33.824Z"}, {"duration": 13, "start_time": "2025-05-07T00:08:35.414Z"}, {"duration": 12, "start_time": "2025-05-07T00:08:36.933Z"}, {"duration": 168, "start_time": "2025-05-08T10:15:16.866Z"}, {"duration": 14, "start_time": "2025-05-08T10:15:20.882Z"}, {"duration": 281, "start_time": "2025-05-08T10:15:47.001Z"}, {"duration": 107, "start_time": "2025-05-08T10:15:48.868Z"}, {"duration": 6, "start_time": "2025-05-08T10:15:50.690Z"}, {"duration": 21, "start_time": "2025-05-08T10:15:53.010Z"}, {"duration": 3, "start_time": "2025-05-08T10:15:59.063Z"}, {"duration": 4, "start_time": "2025-05-08T10:16:00.926Z"}, {"duration": 3, "start_time": "2025-05-08T10:16:02.855Z"}, {"duration": 4, "start_time": "2025-05-08T10:16:04.551Z"}, {"duration": 3, "start_time": "2025-05-08T10:16:06.400Z"}, {"duration": 18, "start_time": "2025-05-08T10:16:10.749Z"}, {"duration": 11, "start_time": "2025-05-08T10:16:12.863Z"}, {"duration": 17, "start_time": "2025-05-08T10:16:14.889Z"}, {"duration": 44, "start_time": "2025-05-08T10:16:18.215Z"}, {"duration": 47, "start_time": "2025-05-08T10:16:21.007Z"}, {"duration": 39, "start_time": "2025-05-08T10:16:23.511Z"}, {"duration": 6, "start_time": "2025-05-08T10:16:25.916Z"}, {"duration": 7, "start_time": "2025-05-08T10:16:35.307Z"}, {"duration": 71, "start_time": "2025-05-08T10:18:28.596Z"}, {"duration": 44, "start_time": "2025-05-08T10:18:50.653Z"}, {"duration": 43, "start_time": "2025-05-08T13:59:10.250Z"}, {"duration": 37, "start_time": "2025-05-08T13:59:12.089Z"}, {"duration": 6, "start_time": "2025-05-08T13:59:14.887Z"}], "colab": {"collapsed_sections": ["E0vqbgi9ay0H", "VUC88oWjTJw2"], "provenance": []}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.19"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": true, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 1}